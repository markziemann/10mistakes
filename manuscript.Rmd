---
title: "10 common mistakes that could ruin your enrichment analysis"
date: "`r Sys.Date()`"
output:
  rmdformats::robobook:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
    fig_width: 5
    fig_height: 5
bibliography: 10mistakes.bib
csl: f1000research.csl
---

<strong>Anusuiya Bora<sup>1,2</sup> & Mark Ziemann<sup>1,2</sup></strong>

1. Deakin University, School of Life and Environmental Sciences, Geelong, Australia.

2. Burnet Institute, Melbourne, Australia

(*) Correspondence: mark.ziemann@burnet.edu.au

| Author | ORCID |
| --- | --- |
| Mark Ziemann | 0000-0002-7688-6974 |
| Anusuiya Bora | 0009-0006-2908-1352 |

Target journal: F1000 Research

# Abstract

Functional enrichment analysis (FEA) is an incredibly powerful way to summarise complex
genomics data into information about the regulation of biological pathways including cellular
metabolism, signalling and immune responses.
About 10,000 scientific articles describe using FEA each year, making it among the most
used techniques in bioinformatics.
While FEA has become a routine part of workflows via myriad software packages and easy-to-use
websites, mistakes can easily creep in due to poor tool design and unawareness among users of
pitfalls.
Here we outline 10 mistakes that undermine the effectiveness of FEA which we commonly see in
research articles.
We provide practical advice on their mitigation.

# Background

PubMed searches indicate keywords like "Pathway analysis" and "Enrichment analysis" appear in title
or abstracts of approximately 10,000 articles per year, and that the number of articles matching these
keywords has increased by a factor of 5.4 between 2014 and 2024.
The purpose of FEA is to understand whether gene categories are collectively
differentially represented in the molecular profile at hand, and involves querying hundreds or
thousands of functional categories which commonly represent gene pathways or ontologies.
There are a variety of methods for FEA, but the main two are over-representation analysis (ORA) and
functional class scoring (FCS) @Khatri2012-yq.
ORA involves selecting genes based on a hard cut-off followed by a test of enrichment (e.g.: Fisher's
exact test) as compared to a background list @Tavazoie1999-as.
Popular ORA tools include websites like DAVID @Sherman2022-kg and software packages like
ClusterProfiler @Wu2021-mg.
FCS involves ranking all detected genes followed by a test to asses whether the distribution of scores
deviates towards the up- or down-regulated directions.
GSEA @Subramanian2005-bd is a stand-alone FCS software with a graphical user interface, and there
are several command-line implementations such as fgsea @Korotkevich2021-xm.

Recommendations on correct application of pathway enrichment have been previously published
[@Tilford2009-kh; @Tipney2010-sy; @Chicco2022-aa; @Zhao2023-av], yet we and others continue to
observe blatant mistakes and methodological deficiencies appearing in peer-reviewed publications at
an alarming rate [@Timmons2015-yb; @Wijesooriya2022-we].
The purpose of this opinion article is to share what our group has learned about successful FEA over
the past 15 years having authored dozens of articles using it and critically examining hundreds of
published articles using the method.

```{r,setup,echo=FALSE}

#knitr::opts_chunk$set(dev = 'svg')

library("kableExtra")
library("png")
library("grid")

```

# 1. Using uncorrected p-values for statistical significance 

AB

```{r,1a,fig.cap="Figure 1A. Impact of FDR correction of p-values on the number of \'significant\' gene sets.",echo=FALSE,fig.height=3,fig.width=3}

mypng = readPNG('img/1a.png')
grid.raster(mypng, x=0.5, y=0.5, width=1)

```


```{r,1b,fig.cap="Figure 1B. FDR control reduces false positives.",echo=FALSE,fig.height=4,fig.width=4}

mypng = readPNG('img/1b.png')
grid.raster(mypng, x=0.5, y=0.5, width=1)

```

# 2. Not using a background gene list 

AB

```{r,2a,fig.cap="Figure 2A. Impact of background list on the number of significant gene sets. Example dataset.",echo=FALSE,fig.height=3,fig.width=3}

mypng = readPNG('img/2a.png')
grid.raster(mypng, x=0.5, y=0.5, width=1)

```

```{r,2b,fig.cap="Figure 2B. Impact of background list on the number of significant gene sets. 100 simulations.",echo=FALSE,fig.height=4,fig.width=4}

mypng = readPNG('img/2b.png')
grid.raster(mypng, x=0.5, y=0.5, width=1)

```

```{r,2c,fig.cap="Figure 2C. Gene sets consistently appearing as false positives include those related to cancer.",echo=FALSE,fig.height=4,fig.width=4}

mypng = readPNG('img/2c.png')
grid.raster(mypng, x=0.5, y=0.5, width=1)

```


# 3. Using a tool that doesn’t report enrichment scores 

FDR values can tell us whether something is statically significant, but it doesn’t directly
indicate whether there will be any biological impact.
For that, we need some measure of effect size.
In enrichment analysis, we can use an enrichment score as a proxy measure of effect size.
For rank-based tools like GSEA, the enrichment score varies from -1  to +1 denoting the
distribution of genes in a gene set relative to all other genes.
A score of 1.0 would mean that X genes in the set are the X most upregulated, while if a
value is close to 0, it means the distribution of genes is close to what you might get by
random chance.
For over-representation methods like DAVID, the fold enrichment score is often quoted, which
is the odds ratio of genes of a gene set in the list as compared to the background.
Unfortunately, DAVID doesn’t provide the fold enrichment scores in the main results page,
they are only available in the table for download.
Many other common tools don’t even calculate the enrichment scores (looking at you
clusterProfiler), which leaves researchers in the dark about their effect sizes.
Tools that do provide enrichment scores include ShinyGO (web) @Ge2020-lr, GSEA @Subramanian2005-bd
and fgsea (fora) @Korotkevich2021-xm.

# 4. Prioritising results solely by p-value 

Pathway enrichment analysis can return hundreds of significant results, which can be
confusing to interpret.
Many tools by default will sort the results by significance, but this can lead you to
prioritise pathways that are very large but where each gene is only slightly dysregulated.
To demonstrate this, see the results from a typical pathway enrichment analysis result with
p-value prioritisation and with enrichment score prioritisation after removal of
non-significant pathways **(Table 1 and Table 2)**.
P-value prioritisation emphasises generic functions with really large gene sets, while
enrichment score prioritisation highlights much smaller gene sets with highly specific
functions, where each member gene is showing a relatively bigger change in expression.
These more specific gene sets are in general better candidates for downstream validation due
to their explanatory power.

```{r,m4tbl,echo=FALSE}

m4 <- readRDS("m4tbls.Rds")

m4[[3]] |>
  kbl(caption="Table 1. Top upregulated pathways when prioritised by FDR.",row.names=FALSE) |>
  kable_paper("hover", full_width = F)

m4[[1]] |>
  kbl(caption="Table 2. Top upregulated pathways when prioritised by ES. Pathways with FDR>0.05 were excluded.",row.names=FALSE) |>
  kable_paper("hover", full_width = F)

```

# 5. Using gene lists that are too large or too small for ORA 

It’s a common misconception that only differentially expressed genes that meet the FDR
threshold should be submitted to an enrichment test, but this simply isn’t true.
So long as you’re using proper FDR control of your pathways (See #1 above), you can select
genes in any arbitrary way your like.
The caveat here is that enrichment tests (like hypergeometric method) have size ranges of
input gene lists that work best.
We tested different input gene list sizes in ORA and found that 2500 yielded the most (456
with FDR<0.0), while sizes 200 and less yielded very few significant pathways (**Figure 3**).
In the range of 300-1000, there’s a steep increase in the number of significant pathways, and
after that the gradient reduces.
This suggests a sweet spot around 1000, which in our example is 7.6% of the 13,168 genes
detected.
If you want to avoid making arbitrary thresholds (which seem to annoy reviewers) then we’d
suggest using a method like GSEA instead that calculates enrichment from all detected genes.

```{r,5m,fig.cap="Figure 3. Effect of gene list size on number of significant pathways. Up-regulated in red, down-regulated in blue.",echo=FALSE,fig.height=4.5,fig.width=7}

mypng = readPNG('img/5m.png')
grid.raster(mypng, x=0.5, y=.5, width=1)

```

# 6. Combining up and down-regulated genes in the same ORA test 

In some articles we’ve read, we noticed that authors didn’t conduct separate ORA tests for
up- and down-regulated gene lists, instead opting to submit the combined list for ORA.
This isn’t necessarily an error, as it tests the hypothesis that some pathways are
“dysregulated”, a mix of up- and down-regulated genes, that appear at an elevated rate.
The combined approach can miss a lot of results as compared to the separate approach.
According to the results of our example analysis the separate approach identified 355
pathways and the combined approach found only 149, that’s 58% less (see Fig XX).
The combined approach could uniquely identify some pathways, but this is relatively few.
In the example dataset, only 2.2% of results were identified exclusively with the combined
test.

The reason behind this is two-fold.
Firstly, we know that genes in the same pathway are typically correlated with each other
@Gatti2010-tb.
Consider cell cycle genes, or genes responding to pathogens, which are activated in unison
to coordinate a complex biological process.
In a typical differential expression experiment after a stimulus, this results in pathways
that are predominantly up or down regulated, but rarely a mix of up and down.
Due to this phenomenon, the up and down lists each have relatively strong enrichments, but
they are diluted when combined @Hong2014-yn.
Based on this, failing to report data of the separate approach could leave you 58% fewer
results, and an incomplete picture of what's happening at the molecular level.

```{r,6m,fig.cap="Figure 6. Combining up and downregulated genes into one ORA test yields far fewer results.",echo=FALSE,fig.height=3,fig.width=5}

mypng = readPNG('img/6m.png')
grid.raster(mypng, x=0.5, y=.5, width=1)

```

# 7. Bad visualisation 

AB

# 8. Using shallow gene annotations 

One of the most important decisions you’ll make when doing a pathway enrichment analysis is
selecting the database to query.
There are many options to consider, both proprietary and open source.
When choosing, consider whether the database contains the gene sets that you a priori
suspect will be altered in the profile you’re looking at.
Secondly consider the breadth and depth of the pathway library, this will be where the
unexpected discoveries may occur, and it pays to use a comprehensive one to capture as many
aspects of your data as possible.
To demonstrate this, see how KEGG legacy and KEGG Medicus seem tiny when compared to Reactome,
which is itself dwarfed by Gene Ontology’s Biological Process (GOBP; Table 3).
Consequently, the results obtained are substantially richer for Reactome and GOBP as compared
to KEGG libraries.

```{r,m8tbl,echo=FALSE}

m8 <- readRDS("m8tbl.Rds")
m8 |>
  kbl(caption="Table 3. Size metrics of selected gene set libraries, and the number of differentially regulated pathways (FDR<0.05).") |>
  kable_paper("hover", full_width = F)

```

# 9. Using outdated gene identifiers and gene sets 

One great thing about working with omics data is that databases like GEO are loaded with old
data sets that we can reanalyse with new pathway databases and software tools to eke out
further insights.
When the data is several years old, we should use the processed data with caution, as many
gene names may have since changes.
For example, Illumina’s EPIC DNA Methylation microarray was released in 2016, and in the
following eight years, 3,253 of 22,588 gene names have changed (14.4%)
@Ziemann2024-be, meaning that those genes wouldn’t be recognised by the pathway
enrichment software.
To update defunct gene symbols, the HGNChelper R package can help @Oh2020-ku, and it
has the benefit of fixing gene symbols ruined by Excel autocorrect, which are unfortunately
common in GEO @Ziemann2016-hp.
Persistent gene identifiers like Ensembl (eg: ENSG00000180096) and HGNC (eg: HGNC:2879)
are less likely to change over time and would therefore be preferable over gene symbols
(eg: SEPTIN1) for FEA.

The depth of pathway databases increases every year as annotation consortia continue
assimilating functional information from the literature.
Sometimes these increases are fairly large, as shown by the chart of Reactome growth below
(**Figure XX**).
To be certain you have the best possible gene annotation for your analysis, it’s always best
to download the newest version.

Figure XX. Reactome gene set growth.
Gene sets were downloaded from the MSigDB website, except The last bar which represents the
latest gene sets downloaded directly from Reactome, not yet incorporated into MSigDB.

```{r,9m,fig.cap="Figure XX. Reactome gene set growth over time. Gene sets were downloaded from the MSigDB website, except The last bar which represents the latest gene sets downloaded directly from Reactome, not yet incorporated into MSigDB.",echo=FALSE,fig.height=3,fig.width=5}

mypng = readPNG('img/9m.png')
grid.raster(mypng, x=0.5, y=.5, width=1)

```

# 10. Not providing detailed methodological info 

AB

# Conclusion 

More subtle issues:

* Karp, P.D., Midford, P.E., Caspi, R. et al. Pathway size matters: the influence of pathway granularity on over-representation (enrichment analysis) statistics. BMC Genomics 22, 191 (2021). https://doi.org/10.1186/s12864-021-07502-8

* Length Bias Correction in Gene Ontology Enrichment Analysis Using Logistic Regression
Gu Mi ,Yanming Di,Sarah Emerson,Jason S. Cumbie,Jeff H. Chang
Published: October 2, 2012
https://doi.org/10.1371/journal.pone.0046128

* Analyzing gene expression data in terms of gene sets: methodological issues
Jelle J Goeman 1, Peter Bühlmann
Affiliations Expand
PMID: 17303618 DOI: 10.1093/bioinformatics/btm051

* PLoS Biol. 2019 Nov 12;17(11):e3000481. doi: 10.1371/journal.pbio.3000481
Recurrent functional misinterpretation of RNA-seq data caused by sample-specific gene length bias
Shir Mandelboum 1,2, Zohar Manber 3, Orna Elroy-Stein 1,2,*, Ran Elkon 2,3,

* On the influence of several factors on pathway enrichment analysis
Briefings in Bioinformatics, Volume 23, Issue 3, May 2022, bbac143,
Sarah Mubeen, Alpha Tom Kodamullil, Martin Hofmann-Apitius, Daniel Domingo-Fernández

The natural selection of bad science
Paul E. Smaldino and Richard McElreath
Published:01 September 2016 https://doi.org/10.1098/rsos.160384

## Other notes 

* It’s official. ORA is not as sensitive as FCS

* Showing too many results

* Not distinguishing results from multiple tools

# Bibliography

